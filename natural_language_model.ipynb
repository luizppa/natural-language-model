{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74df6502",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "## A natural language processing model with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f51cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/eem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import itertools\n",
    "from time import time\n",
    "import multiprocessing\n",
    "\n",
    "# File management\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from os import path, remove\n",
    "\n",
    "# NLP\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f918060",
   "metadata": {},
   "source": [
    "### Downloading the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1378245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or anomie but rather a harmonious anti authoritarian society in place of what are regarded as authoritarian political structures and coercive economic institutions anarchists advocate \n"
     ]
    }
   ],
   "source": [
    "corpus_uri = 'http://mattmahoney.net/dc/text8.zip'\n",
    "target_name = './corpus.txt'\n",
    "corpus_language = 'english'\n",
    "\n",
    "if not path.exists(target_name):\n",
    "    try:\n",
    "        resp = urlopen(corpus_uri)\n",
    "        file = ZipFile(BytesIO(resp.read()))\n",
    "\n",
    "        target_file = open(target_name, 'w')\n",
    "        for line in file.open(file.namelist()[0]).readlines():\n",
    "            target_file.write(line.decode('utf-8'))\n",
    "        target_file.close()\n",
    "    except:\n",
    "        if path.exists(target_name):\n",
    "            remove(target_name)\n",
    "            \n",
    "corpus = open(target_name, 'r')\n",
    "content = corpus.read()\n",
    "print(content[:1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47823457",
   "metadata": {},
   "source": [
    "### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573d5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into sentences\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "sentences = list(itertools.islice(Text8Corpus(target_name),None))\n",
    "sentences = [[word for word in sentence if word not in stopwords] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e60a0",
   "metadata": {},
   "source": [
    "### Creating and training the language model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "381659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(model, sentences):\n",
    "    t = time()\n",
    "    model.build_vocab(sentences, progress_per=10000)\n",
    "    print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c66f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, sentences, epochs, corpus_size):\n",
    "    t = time()\n",
    "    model.train(sentences, total_examples=corpus_size, epochs=epochs, report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75cc717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(sentences, min_count, window, vector_size, alpha, epochs, sg, corpus_size, model_name):\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    model = Word2Vec(min_count=min_count, window=window, vector_size=vector_size, alpha=0.001, workers=cores-1, sg=sg)\n",
    "    corpus_size = model.corpus_count if corpus_size == 0 else corpus_size\n",
    "    \n",
    "    build_vocabulary(model, sentences)\n",
    "    train(model, sentences, epochs, corpus_size)\n",
    "    \n",
    "    model.save(model_name)\n",
    "    \n",
    "def get_model_name(sg, window, vector_size, epochs, corpus_size):\n",
    "    return \"./models/{sg}-{window}-{vector_size}-{epochs}-{corpus_size}.model\".format(\n",
    "        sg = 'skipgram' if sg == 1 else 'cbow',\n",
    "        window = window,\n",
    "        vector_size = vector_size,\n",
    "        epochs = epochs,\n",
    "        corpus_size = corpus_size\n",
    "    )\n",
    "    \n",
    "def build_if_not_exists(sentences, sg=1, window=2, vector_size=100, epochs=30, corpus_size=0):\n",
    "    model_name = get_model_name(sg, window, vector_size, epochs, corpus_size)\n",
    "    \n",
    "    if path.isfile(model_name):\n",
    "        print('model {} already exists'.format(model_name))\n",
    "    else:\n",
    "        return build_model(\n",
    "            sentences = sentences,\n",
    "            min_count = 10,\n",
    "            window = window,\n",
    "            vector_size = vector_size,\n",
    "            alpha = 0.001,\n",
    "            epochs = epochs,\n",
    "            sg = sg,\n",
    "            corpus_size = corpus_size,\n",
    "            model_name = model_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92f444c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_sizes = [50, 100, 300]\n",
    "windows = [2, 5, 10]\n",
    "corpus_sizes = [math.floor(len(sentences)*.33), math.floor(len(sentences)*.66), len(sentences)]\n",
    "epochs = [10, 20, 30]\n",
    "\n",
    "params = [list(i) for i in itertools.product(windows, vector_sizes, epochs, corpus_sizes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb860159",
   "metadata": {},
   "source": [
    "#### Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1aacde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./models/skipgram-2-50-10-561.model already exists\n",
      "model ./models/skipgram-2-50-10-1122.model already exists\n",
      "model ./models/skipgram-2-50-10-1701.model already exists\n",
      "model ./models/skipgram-2-50-20-561.model already exists\n",
      "model ./models/skipgram-2-50-20-1122.model already exists\n",
      "model ./models/skipgram-2-50-20-1701.model already exists\n",
      "model ./models/skipgram-2-50-30-561.model already exists\n",
      "model ./models/skipgram-2-50-30-1122.model already exists\n",
      "model ./models/skipgram-2-50-30-1701.model already exists\n",
      "model ./models/skipgram-2-100-10-561.model already exists\n",
      "model ./models/skipgram-2-100-10-1122.model already exists\n",
      "model ./models/skipgram-2-100-10-1701.model already exists\n",
      "model ./models/skipgram-2-100-20-561.model already exists\n",
      "model ./models/skipgram-2-100-20-1122.model already exists\n",
      "model ./models/skipgram-2-100-20-1701.model already exists\n",
      "model ./models/skipgram-2-100-30-561.model already exists\n",
      "model ./models/skipgram-2-100-30-1122.model already exists\n",
      "model ./models/skipgram-2-100-30-1701.model already exists\n",
      "model ./models/skipgram-2-300-10-561.model already exists\n",
      "model ./models/skipgram-2-300-10-1122.model already exists\n",
      "model ./models/skipgram-2-300-10-1701.model already exists\n",
      "model ./models/skipgram-2-300-20-561.model already exists\n",
      "model ./models/skipgram-2-300-20-1122.model already exists\n",
      "model ./models/skipgram-2-300-20-1701.model already exists\n",
      "model ./models/skipgram-2-300-30-561.model already exists\n",
      "model ./models/skipgram-2-300-30-1122.model already exists\n",
      "model ./models/skipgram-2-300-30-1701.model already exists\n",
      "model ./models/skipgram-5-50-10-561.model already exists\n",
      "model ./models/skipgram-5-50-10-1122.model already exists\n",
      "model ./models/skipgram-5-50-10-1701.model already exists\n",
      "model ./models/skipgram-5-50-20-561.model already exists\n",
      "model ./models/skipgram-5-50-20-1122.model already exists\n",
      "model ./models/skipgram-5-50-20-1701.model already exists\n",
      "model ./models/skipgram-5-50-30-561.model already exists\n",
      "model ./models/skipgram-5-50-30-1122.model already exists\n",
      "model ./models/skipgram-5-50-30-1701.model already exists\n",
      "model ./models/skipgram-5-100-10-561.model already exists\n",
      "model ./models/skipgram-5-100-10-1122.model already exists\n",
      "model ./models/skipgram-5-100-10-1701.model already exists\n",
      "model ./models/skipgram-5-100-20-561.model already exists\n",
      "model ./models/skipgram-5-100-20-1122.model already exists\n",
      "model ./models/skipgram-5-100-20-1701.model already exists\n",
      "model ./models/skipgram-5-100-30-561.model already exists\n",
      "model ./models/skipgram-5-100-30-1122.model already exists\n",
      "model ./models/skipgram-5-100-30-1701.model already exists\n",
      "model ./models/skipgram-5-300-10-561.model already exists\n",
      "model ./models/skipgram-5-300-10-1122.model already exists\n",
      "model ./models/skipgram-5-300-10-1701.model already exists\n",
      "model ./models/skipgram-5-300-20-561.model already exists\n",
      "model ./models/skipgram-5-300-20-1122.model already exists\n",
      "model ./models/skipgram-5-300-20-1701.model already exists\n",
      "model ./models/skipgram-5-300-30-561.model already exists\n",
      "model ./models/skipgram-5-300-30-1122.model already exists\n",
      "model ./models/skipgram-5-300-30-1701.model already exists\n",
      "model ./models/skipgram-10-50-10-561.model already exists\n",
      "model ./models/skipgram-10-50-10-1122.model already exists\n",
      "model ./models/skipgram-10-50-10-1701.model already exists\n",
      "model ./models/skipgram-10-50-20-561.model already exists\n",
      "model ./models/skipgram-10-50-20-1122.model already exists\n",
      "model ./models/skipgram-10-50-20-1701.model already exists\n",
      "model ./models/skipgram-10-50-30-561.model already exists\n",
      "model ./models/skipgram-10-50-30-1122.model already exists\n",
      "model ./models/skipgram-10-50-30-1701.model already exists\n",
      "model ./models/skipgram-10-100-10-561.model already exists\n",
      "model ./models/skipgram-10-100-10-1122.model already exists\n",
      "model ./models/skipgram-10-100-10-1701.model already exists\n",
      "model ./models/skipgram-10-100-20-561.model already exists\n",
      "model ./models/skipgram-10-100-20-1122.model already exists\n",
      "model ./models/skipgram-10-100-20-1701.model already exists\n",
      "model ./models/skipgram-10-100-30-561.model already exists\n",
      "model ./models/skipgram-10-100-30-1122.model already exists\n",
      "model ./models/skipgram-10-100-30-1701.model already exists\n",
      "model ./models/skipgram-10-300-10-561.model already exists\n",
      "model ./models/skipgram-10-300-10-1122.model already exists\n",
      "model ./models/skipgram-10-300-10-1701.model already exists\n",
      "model ./models/skipgram-10-300-20-561.model already exists\n",
      "model ./models/skipgram-10-300-20-1122.model already exists\n",
      "model ./models/skipgram-10-300-20-1701.model already exists\n",
      "model ./models/skipgram-10-300-30-561.model already exists\n",
      "model ./models/skipgram-10-300-30-1122.model already exists\n",
      "model ./models/skipgram-10-300-30-1701.model already exists\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    build_if_not_exists(sentences, 1, param[0], param[1], param[2], param[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51d234",
   "metadata": {},
   "source": [
    "#### Cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2f243d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./models/cbow-2-50-10-561.model already exists\n",
      "model ./models/cbow-2-50-10-1122.model already exists\n",
      "model ./models/cbow-2-50-10-1701.model already exists\n",
      "model ./models/cbow-2-50-20-561.model already exists\n",
      "model ./models/cbow-2-50-20-1122.model already exists\n",
      "model ./models/cbow-2-50-20-1701.model already exists\n",
      "model ./models/cbow-2-50-30-561.model already exists\n",
      "model ./models/cbow-2-50-30-1122.model already exists\n",
      "model ./models/cbow-2-50-30-1701.model already exists\n",
      "model ./models/cbow-2-100-10-561.model already exists\n",
      "model ./models/cbow-2-100-10-1122.model already exists\n",
      "model ./models/cbow-2-100-10-1701.model already exists\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.47 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.44 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.4 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.17 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.16 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.18 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.16 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.14 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.14 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.29 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.44 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.26 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 3.4 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 3.33 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 3.38 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.54 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.45 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.4 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.11 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.17 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.17 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 0.77 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 0.77 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 0.79 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.61 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.56 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.5 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.28 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.34 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.33 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.34 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.26 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 1.3 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.55 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.29 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.15 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 3.34 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 3.21 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 3.13 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.4 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.4 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.41 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.11 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.14 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 2.17 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 0.71 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.42 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.42 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.42 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.13 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.14 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.16 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.15 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.14 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 1.14 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.3 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.28 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 2.31 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 3.43 mins\n",
      "Time to build vocab: 0.05 mins\n",
      "Time to train the model: 3.46 mins\n",
      "Time to build vocab: 0.04 mins\n",
      "Time to train the model: 3.47 mins\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    build_if_not_exists(sentences, 0, param[0], param[1], param[2], param[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21574586",
   "metadata": {},
   "source": [
    "### Retrieving a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "820a5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(corpus_size, sg=1, window=2, vector_size=100, epochs=30):\n",
    "    model_name = get_model_name(sg, window, vector_size, epochs, corpus_size)\n",
    "    \n",
    "    if path.isfile(model_name):\n",
    "        return Word2Vec.load(model_name).wv\n",
    "    else:\n",
    "        print('Model not trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25319f50",
   "metadata": {},
   "source": [
    "### Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a87e308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(model, word, is_to, as_word):\n",
    "    result = model.most_similar(negative=[word], positive=[is_to, as_word])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "10e23827",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(corpus_size=len(sentences), sg=1, window=5, vector_size=200, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "abb77a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ontario'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(model, word='germany', is_to='berlin', as_word='canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "06577101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sun', 0.8934993147850037),\n",
       " ('planet', 0.8837549686431885),\n",
       " ('lunar', 0.8803530931472778),\n",
       " ('jupiter', 0.8790703415870667),\n",
       " ('venus', 0.8754491209983826),\n",
       " ('orbit', 0.8723046779632568),\n",
       " ('eclipse', 0.8718109130859375),\n",
       " ('moons', 0.8517736792564392),\n",
       " ('planets', 0.8502889275550842),\n",
       " ('sky', 0.8460605144500732)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['moon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1f9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
